{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVJLi5nRZf_M",
    "outputId": "5a9a8d63-253f-44cf-836e-1b5436d6117c"
   },
   "outputs": [],
   "source": [
    "#%%shell\n",
    "\n",
    "# Download TorchVision repo to use some files from\n",
    "# references/detection\n",
    "#git clone https://github.com/pytorch/vision.git\n",
    "#cd vision\n",
    "#git checkout v0.3.0\n",
    "\n",
    "#cp references/detection/utils.py ../\n",
    "#cp references/detection/transforms.py ../\n",
    "#cp references/detection/coco_eval.py ../\n",
    "#cp references/detection/engine.py ../\n",
    "#cp references/detection/coco_utils.py ../\n",
    "#pip install pycocotools torchvision\n",
    "#pip install Pillow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEE9-UPiE6a4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and list no of classes in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCsxIJCLE6az",
    "outputId": "b55926af-fcf7-4476-9f8c-af56c34465d8"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../train.csv')\n",
    "classes = list(df['category_id'].unique())\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset class to supply images and annotations directly from a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UubBuzn8E6a7"
   },
   "outputs": [],
   "source": [
    "class PersonCarDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_folder, csv_file, transforms=None):\n",
    "        self.img_folder = img_folder\n",
    "        self.transforms = transforms\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.ids = list(self.dataframe['file_name'].unique())\n",
    "        print(len(self.ids))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        annos = self.dataframe[self.dataframe['file_name']==img_id]\n",
    "        img = Image.open(os.path.join(self.img_folder, img_id))\n",
    "\n",
    "        num_objs = annos.shape[0]\n",
    "\n",
    "        # The input should be [xmin, ymin, xmax, ymax]\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for idx,row in annos.iterrows():\n",
    "            xmin = row['xmin']\n",
    "            ymin = row['ymin']\n",
    "            xmax = row['xmax']\n",
    "            ymax = row['ymax']\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            labels.append(row['category_id'])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        # Size of bbox (Rectangular)\n",
    "        areas = []\n",
    "        for idx,row in annos.iterrows():\n",
    "            areas.append(row['w']*row['h'])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        # Annotation is in dictionary format\n",
    "        my_annotation = {}\n",
    "        my_annotation[\"boxes\"] = boxes\n",
    "        my_annotation[\"labels\"] = labels\n",
    "        my_annotation[\"image_id\"] = torch.tensor([index])\n",
    "        my_annotation[\"area\"] = areas\n",
    "        my_annotation[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, my_annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeHUOejAE6a9"
   },
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    custom_transforms = []\n",
    "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(custom_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OELAdIjmE6a_",
    "outputId": "82a3f52f-ce5a-4172-c9ce-a02389aec608"
   },
   "outputs": [],
   "source": [
    "train_dataset = PersonCarDataset(img_folder='../trainval/images',\n",
    "                          csv_file='../train.csv',\n",
    "                          transforms=get_transform())\n",
    "test_dataset = PersonCarDataset(img_folder='./trainval/images',\n",
    "                          csv_file='../test.csv',\n",
    "                          transforms=get_transform())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train and test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSmWd23hE6bC"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Batch size\n",
    "batch_size = 4\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYkYuswfE6bF",
    "outputId": "8c85aa34-c52e-43c7-fa7f-3485b6d91200"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pectFpQE6bH"
   },
   "outputs": [],
   "source": [
    "#for imgs, annotations in data_loader:\n",
    "#    print(len(annotations),len(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model architecture with pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDUs0tb5E6bJ"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, len(classes)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5VFCOMdE6bR",
    "outputId": "82ad6ecf-f1b1-4c06-c962-460beb512d1e"
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBVpG0f9E6bT"
   },
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oanNEUFCE6bV",
    "outputId": "e841b6eb-da9b-4a68-a511-8f8c51fb0594"
   },
   "outputs": [],
   "source": [
    "len_train,len_test = len(train_data_loader),len(test_data_loader)\n",
    "print(len_train,len_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training and save on each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d0_PF0m3E6bX",
    "outputId": "366acb13-929c-4faa-fa5a-5bff01587aa9"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1,15):\n",
    "    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=5)\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, test_data_loader, device=device)\n",
    "    torch.save(model,f'./stage2_epoch_{epoch}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-kCpWqSWjsD"
   },
   "outputs": [],
   "source": [
    "def test_prediction(inp_model,pos):\n",
    "  img, _ = test_dataset[pos]\n",
    "  inp_model.eval()\n",
    "  with torch.no_grad():\n",
    "      prediction = model([img.to(device)])\n",
    "  image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "  return image,prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYhOhMin-2C8"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageEnhance\n",
    "color_map = {1:'green',2:'red'}\n",
    "def visualize(img,prediction,threshold=0.6):\n",
    "  preds = len(prediction[0]['boxes'])\n",
    "  from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  for i in range(0,preds):\n",
    "      box = list(prediction[0]['boxes'])[i]\n",
    "      label = int(prediction[0]['labels'][i])\n",
    "      score = float(prediction[0]['scores'][i])\n",
    "      if (score>=threshold):\n",
    "        draw.rectangle(((box[0],box[1]), (box[2], box[3])),outline=color_map[label])\n",
    "        draw.text((box[0], box[1]), str(score),color=color_map[label])\n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load nth saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um5t6xAlODcr"
   },
   "outputs": [],
   "source": [
    "loaded_model = torch.load('./stage2_epoch_7.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise inference on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "nnxaEwlB_iqZ",
    "outputId": "99bc6afd-f53d-458d-d569-ec1eb310a066"
   },
   "outputs": [],
   "source": [
    "image,prediction = test_prediction(loaded_model,42)\n",
    "visualize(image,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywa9uVy8PNx0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PyTorchFasterRCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
